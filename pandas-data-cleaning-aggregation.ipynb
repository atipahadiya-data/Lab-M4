{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa8bc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"sales_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0906190f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET INSPECTION ===\n",
      "Shape: (6, 5)\n",
      "\n",
      "Data types:\n",
      "order_id      int64\n",
      "region          str\n",
      "product         str\n",
      "quantity    float64\n",
      "price         int64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "order_id    0\n",
      "region      0\n",
      "product     0\n",
      "quantity    1\n",
      "price       0\n",
      "dtype: int64\n",
      "\n",
      "First few rows:\n",
      "   order_id region   product  quantity  price\n",
      "0      4001   East  Keyboard       2.0   1500\n",
      "1      4002   West     Mouse       NaN    500\n",
      "2      4003   East   Monitor       1.0  12000\n",
      "3      4004  South  Keyboard       1.0   1500\n",
      "4      4005   West   Monitor       2.0  12000\n",
      "\n",
      "Duplicate rows: 1\n"
     ]
    }
   ],
   "source": [
    "#Inspect shape, data types, and missing values:\n",
    "print(\"=== DATASET INSPECTION ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nFirst few rows:\\n{df.head()}\")\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b4d594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before removing duplicates: 6\n",
      "Rows after removing duplicates: 5\n"
     ]
    }
   ],
   "source": [
    "#Remove duplicate rows:\n",
    "print(f\"Rows before removing duplicates: {len(df)}\")\n",
    "df_clean = df.drop_duplicates()\n",
    "print(f\"Rows after removing duplicates: {len(df_clean)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9df6c8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows before dropping missing quantity: 5\n",
      "Rows after dropping missing quantity: 4\n"
     ]
    }
   ],
   "source": [
    "#Drop rows with missing quantity:\n",
    "print(f\"\\nRows before dropping missing quantity: {len(df_clean)}\")\n",
    "df_clean = df_clean.dropna(subset=[\"quantity\"])\n",
    "print(f\"Rows after dropping missing quantity: {len(df_clean)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebaeeaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATA TYPES AFTER CLEANING ===\n",
      "order_id      int64\n",
      "region          str\n",
      "product         str\n",
      "quantity    float64\n",
      "price         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Ensure numeric columns are correctly typed:\n",
    "df_clean[\"quantity\"] = pd.to_numeric(df_clean[\"quantity\"], errors='coerce')\n",
    "df_clean[\"price\"] = pd.to_numeric(df_clean[\"price\"], errors='coerce')\n",
    "\n",
    "print(\"\\n=== DATA TYPES AFTER CLEANING ===\")\n",
    "print(df_clean.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70d767fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLEANING VERIFICATION ===\n",
      "Missing values:\n",
      "order_id    0\n",
      "region      0\n",
      "product     0\n",
      "quantity    0\n",
      "price       0\n",
      "dtype: int64\n",
      "Duplicates: 0\n",
      "\n",
      "Cleaned dataset:\n",
      "   order_id region   product  quantity  price\n",
      "0      4001   East  Keyboard       2.0   1500\n",
      "2      4003   East   Monitor       1.0  12000\n",
      "3      4004  South  Keyboard       1.0   1500\n",
      "4      4005   West   Monitor       2.0  12000\n"
     ]
    }
   ],
   "source": [
    "#Verify cleaning results:\n",
    "print(\"\\n=== CLEANING VERIFICATION ===\")\n",
    "print(f\"Missing values:\\n{df_clean.isnull().sum()}\")\n",
    "print(f\"Duplicates: {df_clean.duplicated().sum()}\")\n",
    "print(f\"\\nCleaned dataset:\\n{df_clean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6423179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with revenue:\n",
      "   order_id region   product  quantity  price  revenue\n",
      "0      4001   East  Keyboard       2.0   1500   3000.0\n",
      "2      4003   East   Monitor       1.0  12000  12000.0\n",
      "3      4004  South  Keyboard       1.0   1500   1500.0\n",
      "4      4005   West   Monitor       2.0  12000  24000.0\n"
     ]
    }
   ],
   "source": [
    "#Create revenue column:\n",
    "df_clean[\"revenue\"] = df_clean[\"quantity\"] * df_clean[\"price\"]\n",
    "print(\"Dataset with revenue:\")\n",
    "print(df_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68c18173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== REVENUE BY PRODUCT ===\n",
      "    product  total_revenue\n",
      "1   Monitor        36000.0\n",
      "0  Keyboard         4500.0\n"
     ]
    }
   ],
   "source": [
    "#Compute total revenue per product:\n",
    "revenue_by_product = df_clean.groupby(\"product\")[\"revenue\"].sum().reset_index()\n",
    "revenue_by_product.columns = [\"product\", \"total_revenue\"]\n",
    "revenue_by_product = revenue_by_product.sort_values(\"total_revenue\", ascending=False)\n",
    "\n",
    "print(\"\\n=== REVENUE BY PRODUCT ===\")\n",
    "print(revenue_by_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "833dda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== REVENUE BY REGION ===\n",
      "  region  total_revenue\n",
      "2   West        24000.0\n",
      "0   East        15000.0\n",
      "1  South         1500.0\n"
     ]
    }
   ],
   "source": [
    "#Compute total revenue per region:\n",
    "revenue_by_region = df_clean.groupby(\"region\")[\"revenue\"].sum().reset_index()\n",
    "revenue_by_region.columns = [\"region\", \"total_revenue\"]\n",
    "revenue_by_region = revenue_by_region.sort_values(\"total_revenue\", ascending=False)\n",
    "\n",
    "print(\"\\n=== REVENUE BY REGION ===\")\n",
    "print(revenue_by_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3729a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: clean_sales.csv\n"
     ]
    }
   ],
   "source": [
    "#Save cleaned dataset:\n",
    "df_clean.to_csv(\"clean_sales.csv\", index=False)\n",
    "print(\"Saved: clean_sales.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9856511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: revenue_by_product.csv\n"
     ]
    }
   ],
   "source": [
    "#Save revenue by product:\n",
    "revenue_by_product.to_csv(\"revenue_by_product.csv\", index=False)\n",
    "print(\"Saved: revenue_by_product.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbf2dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: revenue_by_region.csv\n"
     ]
    }
   ],
   "source": [
    "#Save revenue by region:\n",
    "revenue_by_region.to_csv(\"revenue_by_region.csv\", index=False)\n",
    "print(\"Saved: revenue_by_region.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "296214cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY ===\n",
      "Total records cleaned: 4\n",
      "Total revenue: 40,500.00\n",
      "Products analyzed: 2\n",
      "Regions analyzed: 3\n"
     ]
    }
   ],
   "source": [
    "#Display summary:\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(f\"Total records cleaned: {len(df_clean)}\")\n",
    "print(f\"Total revenue: {df_clean['revenue'].sum():,.2f}\")\n",
    "print(f\"Products analyzed: {len(revenue_by_product)}\")\n",
    "print(f\"Regions analyzed: {len(revenue_by_region)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29e74f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a complete cleaning function:\n",
    "def clean_and_aggregate_sales(input_file):\n",
    "    \"\"\"\n",
    "    Clean sales data and generate revenue summaries.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    df = pd.read_csv(input_file)\n",
    "    print(f\"Loaded {len(df)} records\")\n",
    "    \n",
    "    # Clean data\n",
    "    df_clean = df.drop_duplicates()\n",
    "    df_clean = df_clean.dropna(subset=[\"quantity\"])\n",
    "    df_clean[\"quantity\"] = pd.to_numeric(df_clean[\"quantity\"], errors='coerce')\n",
    "    df_clean[\"price\"] = pd.to_numeric(df_clean[\"price\"], errors='coerce')\n",
    "    \n",
    "    # Calculate revenue\n",
    "    df_clean[\"revenue\"] = df_clean[\"quantity\"] * df_clean[\"price\"]\n",
    "    \n",
    "    # Aggregations\n",
    "    revenue_by_product = df_clean.groupby(\"product\")[\"revenue\"].sum().reset_index()\n",
    "    revenue_by_product.columns = [\"product\", \"total_revenue\"]\n",
    "    revenue_by_product = revenue_by_product.sort_values(\"total_revenue\", ascending=False)\n",
    "    \n",
    "    revenue_by_region = df_clean.groupby(\"region\")[\"revenue\"].sum().reset_index()\n",
    "    revenue_by_region.columns = [\"region\", \"total_revenue\"]\n",
    "    revenue_by_region = revenue_by_region.sort_values(\"total_revenue\", ascending=False)\n",
    "    \n",
    "    # Save outputs\n",
    "    df_clean.to_csv(\"clean_sales.csv\", index=False)\n",
    "    revenue_by_product.to_csv(\"revenue_by_product.csv\", index=False)\n",
    "    revenue_by_region.to_csv(\"revenue_by_region.csv\", index=False)\n",
    "    \n",
    "    print(\"Cleaning and aggregation complete!\")\n",
    "    print(f\"  - Clean records: {len(df_clean)}\")\n",
    "    print(f\"  - Total revenue: {df_clean['revenue'].sum():,.2f}\")\n",
    "    \n",
    "    return df_clean, revenue_by_product, revenue_by_region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d6b6868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 records\n",
      "Cleaning and aggregation complete!\n",
      "  - Clean records: 4\n",
      "  - Total revenue: 40,500.00\n"
     ]
    }
   ],
   "source": [
    "#Execute the function:\n",
    "clean_df, product_rev, region_rev = clean_and_aggregate_sales(\"sales_raw.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
